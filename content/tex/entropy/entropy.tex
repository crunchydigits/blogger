\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsthm}


\newtheorem{definition}{Definition}


\title{Entropy and Information}
\author{Robert deCarvalho}
\date{}							% Activate to display a given date or no date
\begin{document}
\maketitle


\section{Introduction}
Entropy is one of those words that many people use, but few really understand.
This might be because the concept is invoked in seemingly very different
contexts.  For example, your physics teacher might have told you, ``The entropy
of the universe is increasing!'' Or perhaps you encountered the word while
reading about compression. ``This algorithm compressed our file to within
10\% of the entropy limit.''  Or maybe you vaguely remember entropy as something
your chemistry teacher told you about and maybe it had something to do with
reactions, but you can't quite remember.  Well, hopefully by the end of this
chapter you will have a decent grasp of what entropy is and how you can make
practical use of it.


\section{A Working Definition of Entropy}
Our quest to understand entropy will start with a simple definition.
\begin{definition}
    Entropy is the amount of information you do not know.
\end{definition}
That's a pretty short definition, but why would you possibly care about how much
information you don't know.  Shouldn't you care much more about you do know?
Also, what does it even mean to talk about an ``amount of informtion?'' You
probably have an intuitive sense of what ``information'' means, but how is it
quantified?  How could you tell if you knew presicely $2.73$ times more about a
topic today than you did yesterday?  As a guide to understanding how information
can be measured, we turn to a contrived example that will illustrate how
information can be quantified.


\subsection{The Library of Information}
Imagine you work at a library containing exactly $1000$ books.  Instead of the
Dewey Decimal System, the books have been given sequential labels from $000$ to
$999$.  The books are arranged onto $100$ shelves each holding $10$ books and
labeled with  two digits corresponding the the first two digits of all the books
it contains.  When patrons enter the library, they present you with slips of
paper containing the three-digit number of the book they'd like to check out.
It is your job to retrieve the correct book from the shelves.

In this scenario, what information do the three digits on that slip of paper
provide you?  By looking at the first two digits on the slip of paper, you can
navigate directly to the shelve containing the relevant book.  Looking at that
last digit tells you how far along the shelf the book lies, and you can locate
it perfectly on the first try.  Because of the way the libary has been
orgainized, those three digits are all you need to know to locate the book.


Now consider a modified scenario where someone has come in and covered all the
books with identical dust jackets.  Now there is no way to distinguish between
the books because they all look the same.  Furthermore, their three-digit call
numbers are now obscured.  This has placed you in quite a quandry, because this
same prankster has gone to each shelf and scrambled the order of the books.
Fortunately, no books have moved shelves, but they are completely out of order
within that shelf.





Imagine, if you will, that you work the front desk at a library, which holds
exactly $1000$ books in its collection.  The collector for this particular
library is a bit eccentric and has decided that instead of using the Dewey
decimal system for labeling the books, they will each be identified with
sequential numbers starting with $000$ and going up to $999$.  Instead of
labeling the spine of the books



which has have a library in which I have collected exactly
$1000$ books. I have been very careful in selecting the titles that go into my
collection. I have only included books whos title's begin with the first ten
letters of the alphabet, A-J. As a matter of fact, there are exactly $100$ books
that begin with A, $100$ books that begin with B, and so on all the way through
the letter J.  I now have $1000$ books equally distributed among my $10$ bins.

MAYBE INSTEAD OF USING ALPHABETIZED BOOKS, USE CALL NUMBERS BECAUSE THIS
WILL MORE CLOSELY TIE INTO ENTROPY

\end{document}  
